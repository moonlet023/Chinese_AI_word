import os
import cv2
import json
import numpy as np
from pathlib import Path
from flask import Flask, render_template, request, jsonify, send_from_directory
from werkzeug.utils import secure_filename
import base64
from io import BytesIO
from PIL import Image

# TensorFlow å°å…¥ï¼ˆå»¶é²å°å…¥ä»¥è™•ç†éŒ¯èª¤ï¼‰
tf = None
try:
    import tensorflow as tf
    print("âœ… TensorFlow æˆåŠŸè¼‰å…¥")
except ImportError:
    print("âŒ TensorFlow æœªå®‰è£")

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB æœ€å¤§æª”æ¡ˆå¤§å°

# ç¢ºä¿ä¸Šå‚³ç›®éŒ„å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# å…¨åŸŸè®Šæ•¸
model = None
class_names = []
IMG_SIZE = 64

def _infer_model_input_size_and_channels():
    """å¾å·²è¼‰å…¥çš„æ¨¡å‹æ¨æ–·è¼¸å…¥å¤§å°å’Œé€šé“æ•¸ï¼Œå›å‚³ (width, height, channels)
    è‹¥ç„¡æ³•æ¨æ–·ï¼Œå›å‚³ (IMG_SIZE, IMG_SIZE, 1)
    """
    try:
        # ç•¶æ¨¡å‹å°šæœªè¼‰å…¥æ™‚ï¼Œå›å‚³é è¨­å€¼
        if model is None:
            return (IMG_SIZE, IMG_SIZE, 1)

        # ç›¡é‡å¾ model æ‰¾åˆ° input shape
        shape = None
        # model.input_shape å¸¸è¦‹ç‚º (None, H, W, C) æˆ– (H, W, C)
        if hasattr(model, 'input_shape') and model.input_shape is not None:
            shape = model.input_shape
        elif hasattr(model, 'inputs') and len(model.inputs) > 0:
            try:
                # inputs[0].shape å¯èƒ½æ˜¯ TensorShape
                shape = tuple(model.inputs[0].shape.as_list())
            except Exception:
                shape = tuple(model.inputs[0].shape)

        if shape is None:
            return (IMG_SIZE, IMG_SIZE, 1)

        # Normalize shape to (batch?, H, W, C) or (H, W, C)
        s = list(shape)
        # remove None batch dims
        s = [x for x in s if x is not None]

        # æœ€å¸¸è¦‹æ˜¯ [H, W, C]
        if len(s) == 3:
            h, w, c = s
        elif len(s) == 2:
            # å¯èƒ½æ˜¯ (H, W)
            h, w = s
            c = 1
        else:
            # fallback
            return (IMG_SIZE, IMG_SIZE, 1)

        # è½‰ç‚º intï¼Œä¸¦ä»¥é è¨­å€¼ä½œç‚ºä¿éšª
        h = int(h) if h is not None else IMG_SIZE
        w = int(w) if w is not None else IMG_SIZE
        c = int(c) if c is not None else 1

        # å›å‚³é †åºç‚º (width, height, channels) ä»¥æ–¹ä¾¿ cv2.resize
        return (w, h, c)
    except Exception:
        return (IMG_SIZE, IMG_SIZE, 1)

def _find_latest_results_json():
    """å°‹æ‰¾æœ€è¿‘æ›´æ–°çš„çµæœ JSONï¼ˆæ”¯æ´å¤šç¨®å‘½åæ¨£å¼ï¼‰"""
    patterns = [
        'ultra_training_results_*.json',
        'high_accuracy_*_results_*.json',
        'practical_results_*.json',
        'quick_test_results_*.json',
        'model_results_*.json',
    ]
    candidates = []
    for pat in patterns:
        candidates.extend(list(Path('.').glob(pat)))
    if not candidates:
        return None
    return max(candidates, key=lambda x: x.stat().st_mtime)


def load_model_and_classes():
    """è¼‰å…¥æœ€ä½³æ¨¡å‹å’Œé¡åˆ¥åç¨±"""
    global model, class_names
    
    if tf is None:
        print("âŒ TensorFlow æœªå¯ç”¨ï¼Œç„¡æ³•è¼‰å…¥æ¨¡å‹")
        return False
    
    # ä½¿ç”¨æœ€æ–°çš„é«˜æº–ç¢ºç‡æ¨¡å‹ï¼ˆç”±æ›´æ–°å™¨æ³¨å…¥æ­¤æª”åï¼‰
    model_file = "ultra_final_model.h5"
    
    if not os.path.exists(model_file):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")
        return False
    
    try:
        model = tf.keras.models.load_model(model_file)
        print(f"âœ… é«˜æº–ç¢ºç‡æ¨¡å‹è¼‰å…¥æˆåŠŸ: {model_file}")

    # å˜—è©¦å¾æœ€è¿‘çš„çµæœ JSON è®€å–è³‡è¨Šï¼ˆaccuracyã€class_namesï¼‰
        latest_json = _find_latest_results_json()
        results = None
        if latest_json is not None:
            try:
                with open(latest_json, 'r', encoding='utf-8') as f:
                    results = json.load(f)
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•è®€å–çµæœæª”æ¡ˆ {latest_json}: {e}")

        # é¡¯ç¤ºæº–ç¢ºç‡ï¼ˆè‹¥çµæœæª”æä¾›ï¼‰
        acc = None
        if isinstance(results, dict):
            for k in ['overall_accuracy', 'val_accuracy', 'accuracy', 'best_val_accuracy']:
                if k in results and isinstance(results[k], (int, float)):
                    acc = float(results[k])
                    break
            if acc is not None:
                print(f"   æ¨¡å‹æº–ç¢ºç‡: {acc:.1f}%")

        # è¨­ç½®é¡åˆ¥åç¨±ï¼šå„ªå…ˆä½¿ç”¨æ¨¡å‹æ—çš„é¡åˆ¥æ¸…å–®æª”æ¡ˆï¼Œå…¶æ¬¡ä½¿ç”¨çµæœæª” class_namesï¼Œæœ€å¾Œæ‰å¾è³‡æ–™å¤¾è¼‰å…¥
        loaded_mapping = False

        # 1) å˜—è©¦ ultra_classes.json æˆ– *classes*.json
        sidecar_jsons = list(Path('.').glob('ultra_classes.json')) + list(Path('.').glob('*classes*.json'))
        if sidecar_jsons:
            # å–æœ€è¿‘çš„
            best_sidecar = max(sidecar_jsons, key=lambda x: x.stat().st_mtime)
            try:
                with open(best_sidecar, 'r', encoding='utf-8') as f:
                    sc = json.load(f)
                if isinstance(sc, dict) and isinstance(sc.get('class_names'), list) and sc['class_names']:
                    class_names = sc['class_names']
                    loaded_mapping = True
                    print(f"âœ… å¾ {best_sidecar.name} è¼‰å…¥ {len(class_names)} å€‹å­—ç¬¦é¡åˆ¥")
            except Exception as e:
                print('âš ï¸ è®€å–é¡åˆ¥æ¸…å–®æª”æ¡ˆå¤±æ•—:', e)

        # 2) è‹¥ sidecar ç„¡ï¼Œä½¿ç”¨çµæœæª”æä¾›çš„ class_names
        if not loaded_mapping and isinstance(results, dict) and isinstance(results.get('class_names'), list) and results['class_names']:
            class_names = results['class_names']
            loaded_mapping = True
            print(f"âœ… å¾çµæœæª”è¼‰å…¥ {len(class_names)} å€‹å­—ç¬¦é¡åˆ¥")

        # 3) ä»ç„¡ -> å¾è³‡æ–™ç›®éŒ„è¼‰å…¥ï¼ˆå¯èƒ½èˆ‡å¯¦éš›æ¨¡å‹ä¸ä¸€è‡´ï¼Œåƒ…ç‚ºå¾Œå‚™ï¼‰
        if not loaded_mapping:
            load_class_names()
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return False

def load_class_names():
    """è¼‰å…¥å­—ç¬¦é¡åˆ¥åç¨±"""
    global class_names
    
    sample_dir = Path('./data/sample')
    if sample_dir.exists():
        class_names = sorted([d.name for d in sample_dir.iterdir() if d.is_dir()])
        print(f"âœ… è¼‰å…¥ {len(class_names)} å€‹å­—ç¬¦é¡åˆ¥")
    else:
        print("âŒ æœªæ‰¾åˆ° sample è³‡æ–™ç›®éŒ„")

def preprocess_image(image_path_or_array, target_size=None):
    """
    é è™•ç†åœ–ç‰‡ä»¥ç¬¦åˆæ¨¡å‹è¼¸å…¥è¦æ±‚
    
    Args:
        image_path_or_array: åœ–ç‰‡è·¯å¾‘æˆ– numpy array
        target_size: ç›®æ¨™å¤§å°
    
    Returns:
        è™•ç†å¾Œçš„åœ–ç‰‡ array
    """
    try:
        # è®€å–åœ–ç‰‡ï¼ˆæ”¯æ´è·¯å¾‘ã€PIL Imageã€numpy arrayï¼‰
        if isinstance(image_path_or_array, (str, Path)):
            img = cv2.imread(str(image_path_or_array), cv2.IMREAD_UNCHANGED)
        elif 'PIL' in str(type(image_path_or_array)):
            # PIL Image
            pil_img = image_path_or_array
            img = np.array(pil_img)
        else:
            img = image_path_or_array

        if img is None:
            raise ValueError("ç„¡æ³•è®€å–åœ–ç‰‡")

        # æ¨æ–·æ¨¡å‹æœŸæœ›çš„è¼¸å…¥å°ºå¯¸èˆ‡é€šé“
        target_w, target_h, target_c = _infer_model_input_size_and_channels()

        # å¤–éƒ¨ override
        if target_size is not None:
            target_w, target_h = target_size

        # è‹¥åœ–ç‰‡ç‚º PIL è½‰ numpy å¾Œï¼Œå½¢ç‹€å¯èƒ½æ˜¯ (H,W) or (H,W,3) or (H,W,4)
        if img.ndim == 3 and img.shape[2] == 4:
            # RGBA -> RGB
            img = img[:, :, :3]

        # è‹¥ç‚ºå½©è‰² (3)ï¼Œè½‰ç‚ºç°éšï¼ˆå¤§å¤šæ•¸æ¨¡å‹ç‚ºç°éšï¼‰ï¼Œä½†è‹¥æ¨¡å‹æœŸæœ›å¤šé€šé“å‰‡ä¿ç•™
        if img.ndim == 3 and img.shape[2] == 3 and int(target_c) == 1:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        elif img.ndim == 2:
            gray = img
        elif img.ndim == 3 and int(target_c) != 1:
            # æ¨¡å‹éœ€è¦å¤šé€šé“ (ä¾‹å¦‚ 3)ï¼Œç›´æ¥è½‰æ›åˆ° BGR ä¸¦ä½¿ç”¨
            # OpenCV uses BGR ordering
            if img.shape[2] == 3:
                img_rgb = img
            else:
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            # resize å½©è‰²
            img_resized_color = cv2.resize(img_rgb, (int(target_w), int(target_h)), interpolation=cv2.INTER_AREA)
            img_out = img_resized_color.astype(np.float32) / 255.0
            img_out = np.expand_dims(img_out, axis=0)
            return img_out
        else:
            # å…œåº•
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim == 3 else img

        # resize grayscale
        img_resized = cv2.resize(gray, (int(target_w), int(target_h)), interpolation=cv2.INTER_AREA)

        # normalize
        img_resized = img_resized.astype(np.float32) / 255.0

        # channel handling
        if int(target_c) == 1:
            img_out = np.expand_dims(img_resized, axis=-1)
        else:
            # replicate gray to channels
            img_out = np.stack([img_resized] * int(target_c), axis=-1)

        # add batch
        img_out = np.expand_dims(img_out, axis=0)

        return img_out

    except Exception as e:
        print(f"âŒ åœ–ç‰‡é è™•ç†éŒ¯èª¤: {e}")
        return None

@app.route('/')
def index():
    """ä¸»é é¢"""
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    """é æ¸¬æ‰‹å¯«å­—ç¬¦"""
    if model is None:
        return jsonify({'error': 'æ¨¡å‹æœªè¼‰å…¥'}), 500
    
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰æª”æ¡ˆä¸Šå‚³
        if 'file' not in request.files:
            return jsonify({'error': 'æœªæ‰¾åˆ°æª”æ¡ˆ'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æœªé¸æ“‡æª”æ¡ˆ'}), 400
        
        # ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)
        
        # é è™•ç†åœ–ç‰‡ï¼ˆæœƒè‡ªå‹•ä¾æ¨¡å‹è¼¸å…¥å¤§å°èª¿æ•´ï¼‰
        processed_img = preprocess_image(file_path, target_size=None)
        if processed_img is None:
            return jsonify({'error': 'åœ–ç‰‡è™•ç†å¤±æ•—'}), 400
        
        # é€²è¡Œé æ¸¬
        predictions = model.predict(processed_img, verbose=0)
        
        # ç²å–é æ¸¬çµæœ
        predicted_class_idx = np.argmax(predictions[0])
        confidence = float(predictions[0][predicted_class_idx])
        
        # ç²å–å‰ 5 å€‹é æ¸¬
        top_5_idx = np.argsort(predictions[0])[-5:][::-1]
        top_5_predictions = [
            {
                'character': class_names[idx] if idx < len(class_names) else f'Class_{idx}',
                'confidence': float(predictions[0][idx])
            }
            for idx in top_5_idx
        ]
        
        # æ¸…ç†æš«å­˜æª”æ¡ˆ
        try:
            os.remove(file_path)
        except:
            pass
        
        return jsonify({
            'predicted_character': class_names[predicted_class_idx] if predicted_class_idx < len(class_names) else f'Class_{predicted_class_idx}',
            'confidence': confidence,
            'top_5': top_5_predictions
        })
        
    except Exception as e:
        print(f"âŒ é æ¸¬éŒ¯èª¤: {e}")
        return jsonify({'error': f'é æ¸¬å¤±æ•—: {str(e)}'}), 500

@app.route('/canvas_predict', methods=['POST'])
def canvas_predict():
    """å¾ç•«å¸ƒé æ¸¬æ‰‹å¯«å­—ç¬¦"""
    if model is None:
        return jsonify({'error': 'æ¨¡å‹æœªè¼‰å…¥'}), 500
    
    try:
        # ç²å– base64 åœ–ç‰‡è³‡æ–™
        data = request.get_json()
        image_data = data['image']
        
        # è§£ç¢¼ base64 åœ–ç‰‡
        image_data = image_data.split(',')[1]  # ç§»é™¤ "data:image/png;base64," å‰ç¶´
        image_binary = base64.b64decode(image_data)
        
        # è½‰æ›ç‚º PIL Image
        pil_image = Image.open(BytesIO(image_binary))
        
        # è½‰æ›ç‚º numpy array
        img_array = np.array(pil_image)
        
        # å¦‚æœæ˜¯ RGBAï¼Œè½‰æ›ç‚º RGB
        if img_array.shape[-1] == 4:
            img_array = img_array[:, :, :3]
        
        # é è™•ç†åœ–ç‰‡ï¼ˆæœƒè‡ªå‹•ä¾æ¨¡å‹è¼¸å…¥å¤§å°èª¿æ•´ï¼‰
        processed_img = preprocess_image(img_array, target_size=None)
        if processed_img is None:
            return jsonify({'error': 'åœ–ç‰‡è™•ç†å¤±æ•—'}), 400
        
        # é€²è¡Œé æ¸¬
        predictions = model.predict(processed_img, verbose=0)
        
        # ç²å–é æ¸¬çµæœ
        predicted_class_idx = np.argmax(predictions[0])
        confidence = float(predictions[0][predicted_class_idx])
        
        # ç²å–å‰ 5 å€‹é æ¸¬
        top_5_idx = np.argsort(predictions[0])[-5:][::-1]
        top_5_predictions = [
            {
                'character': class_names[idx] if idx < len(class_names) else f'Class_{idx}',
                'confidence': float(predictions[0][idx])
            }
            for idx in top_5_idx
        ]
        
        return jsonify({
            'predicted_character': class_names[predicted_class_idx] if predicted_class_idx < len(class_names) else f'Class_{predicted_class_idx}',
            'confidence': confidence,
            'top_5': top_5_predictions
        })
        
    except Exception as e:
        print(f"âŒ ç•«å¸ƒé æ¸¬éŒ¯èª¤: {e}")
        return jsonify({'error': f'é æ¸¬å¤±æ•—: {str(e)}'}), 500

@app.route('/model_info')
def model_info():
    """ç²å–æ¨¡å‹è³‡è¨Š"""
    if model is None:
        return jsonify({'error': 'æ¨¡å‹æœªè¼‰å…¥'}), 500
    
    try:
        latest_result = _find_latest_results_json()
        if latest_result:
            try:
                with open(latest_result, 'r', encoding='utf-8') as f:
                    results = json.load(f)
            except Exception as e:
                results = { 'error': f'è®€å–çµæœæª”æ¡ˆå¤±æ•—: {e}' }

            return jsonify({
                'total_classes': len(class_names),
                'model_results': results,
                'class_names': class_names[:20]  # åªé¡¯ç¤ºå‰ 20 å€‹é¡åˆ¥
            })
        else:
            return jsonify({
                'total_classes': len(class_names),
                'class_names': class_names[:20]
            })
    except Exception as e:
        return jsonify({'error': f'ç²å–æ¨¡å‹è³‡è¨Šå¤±æ•—: {str(e)}'}), 500

@app.route('/supported_classes')
def supported_classes():
    """å›å‚³å®Œæ•´å¯è­˜åˆ¥çš„å­—ç¬¦æ¸…å–®ï¼ˆå¯èƒ½å¾ˆå¤šï¼Œè«‹æ³¨æ„å¤§å°ï¼‰"""
    if model is None:
        return jsonify({'error': 'æ¨¡å‹æœªè¼‰å…¥'}), 500
    return jsonify({
        'total': len(class_names),
        'class_names': class_names
    })

if __name__ == '__main__':
    print("ğŸš€ ç¹é«”ä¸­æ–‡æ‰‹å¯«å­—ç¬¦è­˜åˆ¥ Web æ‡‰ç”¨ç¨‹åº")
    print("=" * 50)
    
    # è¼‰å…¥æ¨¡å‹
    if load_model_and_classes():
        print("ğŸŒ å•Ÿå‹• Web æœå‹™å™¨...")
        app.run(debug=True, host='0.0.0.0', port=5000)
    else:
        print("âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼Œè«‹å…ˆè¨“ç·´æ¨¡å‹")
        print("   åŸ·è¡Œ: python simple_ai_training.py --epochs 10")